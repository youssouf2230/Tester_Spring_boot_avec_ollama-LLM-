# Tester_Spring_boot_avec_ollama-LLM-

#  Spring Boot + Ollama (LLM Local)

    Ce projet démontre comment interagir avec un LLM local (`llama2` via [Ollama](https://ollama.com)) en utilisant une API REST construite avec Spring Boot.

##  Prérequis

    - Java 17+
    - Maven ou Gradle
    - Ollama installé localement : https://ollama.com
    - Modèle téléchargé : `ollama run llama2`

# Démarrer Ollama (en arrière-plan)
    ollama serve
